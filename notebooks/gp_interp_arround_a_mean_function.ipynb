{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Lesson 3 : Mean function & Gaussian processes \n\nBelow some packages to import that will be used for this lesson\n\nCell bellow is here for avoiding scrolling when plot is create within ipython notebook"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%%javascript\nIPython.OutputArea.prototype._should_scroll = function(lines){\n    return false;\n}",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": "IPython.OutputArea.prototype._should_scroll = function(lines){\n    return false;\n}",
            "text/plain": "<IPython.core.display.Javascript object>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Classical package for manipulating\n# array, for plotting and interactiv plots.\nimport pylab as plt\nfrom matplotlib import gridspec\nimport numpy as np\nimport scipy\nimport ipywidgets as widgets\nfrom ipywidgets import interact\nimport itertools\nimport copy\nimport sys\nimport pickle\n\n# Gaussian processes from scikit-learn is used for this lesson.\n# Other packages exist (e.g. george) but for the courses I guess\n# it would be the best because a lot of people in desc are already\n# using scikit-learn. The only suggestion would be about how to fit\n# hyperparameters in a more efficient way, but it will be done with\n# an other packages also broadly used within DESC, which is TreeCorr.\nfrom sklearn import gaussian_process as skl_gp\nfrom sklearn.gaussian_process.kernels import Kernel\n\n# Special implemetation of anisotropic squarred exponential kernel\n# in scikit-learn. Not implemented in scikit-learn originally.\nimport sys\nsys.path.append('/home/nbuser/project')\nfrom kernel import AnisotropicRBF\n\n# treecorr is a package to compute 2-point correlation function.\n# it will be use as an alternative way of Maximum Likelihood described \n# in Rasmussen & Williams 2006 to estimate hyperparameters.\ntry:\n    import treecorr\nexcept:\n    !pip install treecorr\n    import treecorr\n\n# Some import trickery to get all subclasses of sklearn.gaussian_process.kernels.Kernel\n# into the local namespace without doing \"from sklearn.gaussian_process.kernels import *\"\n# and without importing them all manually. Originally developped by Josh Meyers within Piff.\n# Example:\n# kernel = eval_kernel(\"RBF(1)\") instead of\n# kernel = sklearn.gaussian_process.kernels.RBF(1)\ndef eval_kernel(kernel):\n    def recurse_subclasses(cls):\n        out = []\n        for c in cls.__subclasses__():\n            out.append(c)\n            out.extend(recurse_subclasses(c))\n        return out\n    clses = recurse_subclasses(Kernel)\n    for cls in clses:\n        module = __import__(cls.__module__, globals(), locals(), cls)\n        execstr = \"{0} = module.{0}\".format(cls.__name__)\n        exec(execstr, globals(), locals())\n\n    from numpy import array\n\n    try:\n        k = eval(kernel)\n    except (KeyboardInterrupt, SystemExit):\n        raise\n    except Exception as e:  # pragma: no cover\n        raise RuntimeError(\"Failed to evaluate kernel string {0!r}.  \"\n                               \"Original exception: {1}\".format(kernel, e))\n\n    if type(k.theta) is property:\n        raise TypeError(\"String provided was not initialized properly\")\n    return k\n\ndef load_pickle(pickle_file):\n    if sys.version_info[0] < 3:\n        dico = pickle.load(open(pickle_file))\n    else:\n        dico = pickle.load(open(pickle_file, 'rb'), encoding='latin1')\n\n    return dico",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Collecting treecorr\n  Using cached https://files.pythonhosted.org/packages/06/72/0b86c778e815a0611a7fc7bd5239d17ed346d9f382b8733f6cab1b38a06e/TreeCorr-4.0.4.tar.gz\nRequirement already satisfied: numpy in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from treecorr) (1.16.2)\nRequirement already satisfied: cffi in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from treecorr) (1.11.5)\nRequirement already satisfied: pyyaml in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from treecorr) (3.13)\nCollecting LSSTDESC.Coord>=1.1 (from treecorr)\n  Using cached https://files.pythonhosted.org/packages/c4/28/7175cb1c0df002b4435ff25f6f2d92c5ad7417e80f4bdf436783205760cb/LSSTDESC.Coord-1.1.2.tar.gz\nRequirement already satisfied: pycparser in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from cffi->treecorr) (2.19)\nRequirement already satisfied: future in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from LSSTDESC.Coord>=1.1->treecorr) (0.15.2)\nBuilding wheels for collected packages: treecorr, LSSTDESC.Coord\n  Running setup.py bdist_wheel for treecorr ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/nbuser/.cache/pip/wheels/22/6a/04/c7b238b2e07633907026191f5bea54cb27035183045279e173\n  Running setup.py bdist_wheel for LSSTDESC.Coord ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/nbuser/.cache/pip/wheels/5f/d7/aa/627da57d6a75fe0bf63e03d8bb0e8767e804bb9be2c7a05bb7\nSuccessfully built treecorr LSSTDESC.Coord\nInstalling collected packages: LSSTDESC.Coord, treecorr\nSuccessfully installed LSSTDESC.Coord-1.1.2 treecorr-4.0.4\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Exercice 6) Adding a mean function on real SNIa data, impact on GP interpolation (1D):"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "##########################################################################################\n# EXERCICE 6: Adding a mean function on real SNIa data, impact on GP interpolation (1D): #\n##########################################################################################\n\ndic = load_pickle('data/snia_gaussian_process_de_school.pkl')\n\ndef gp_regression(x, new_x, y, kernel, y_err=None):\n    \n    if y_err is None:\n        y_err =np.ones_like(y) *1e-10\n    \n    gp = skl_gp.GaussianProcessRegressor(kernel=kernel, alpha=y_err,\n                                         optimizer=None,\n                                         normalize_y=None)\n    gp.fit(x,y)\n    y_predict, y_std = gp.predict(new_x, return_std=True)\n    log_L = gp.log_marginal_likelihood()\n    return y_predict, y_std, log_L\n\ndef spline_1D(old_binning, mean_function, new_binning):\n    cubic_spline = scipy.interpolate.InterpolatedUnivariateSpline(old_binning,\n                                                                  mean_function)\n    mean_interpolate = cubic_spline(new_binning)\n    return mean_interpolate\n\n\n@interact(sigma = widgets.FloatSlider(value=0.5, min=0.1, max=0.8, step=0.01, description='$\\sigma$:',\n          disabled=False,\n          continuous_update=False,\n          orientation='horizontal',\n          readout=True,\n          readout_format='.2f'), \n          l = widgets.FloatSlider(value=3., min=1., max=15, step=0.1, description='$l$:',\n          disabled=False,\n          continuous_update=False,\n          orientation='horizontal',\n          readout=True,\n          readout_format='.2f'),\n          add_mean=widgets.Checkbox(value=False,\n                                   description='Add mean function',\n                                   disabled=False),\n          sn_name = widgets.Dropdown(options=['SNF20080514-002', 'SNF20050821-007', 'SNF20070802-000'],\n                                     value='SNF20080514-002',\n                                     description='SNIa name:',\n                                     disabled=False,))\ndef plot_samples(sigma, l, add_mean, sn_name):\n    \n    i = 151\n    \n    new_x = np.linspace(-12, 48, 80).reshape((80, 1))\n    Kernel = \"%f * %s(%f)\"%((sigma**2, \"RBF\", l))\n    Kernel = eval_kernel(Kernel)\n    \n    y = copy.deepcopy(dic[sn_name]['y'])\n    y0 = copy.deepcopy(dic[sn_name]['y0'])\n \n    if add_mean:\n        y0_on_y = spline_1D(dic[sn_name]['y0_time'], y0, \n                            dic[sn_name]['y_time'])\n    else:\n        y0_on_y = 0\n    \n    epoch = dic[sn_name]['y_time'].reshape((len(dic[sn_name]['y_time']),1))\n\n    y_pred, y_std, log_L = gp_regression(epoch, new_x, y-y0_on_y, \n                                         Kernel, y_err=dic[sn_name]['y_err'])\n    if add_mean:\n        y0_on_ypredict = spline_1D(dic[sn_name]['y0_time'], y0, \n                                   np.linspace(-12, 48, 80))\n    else:\n        y0_on_ypredict = 0\n        \n    y_pred += y0_on_ypredict\n\n    plt.figure(figsize=(14,8))\n    \n    # Data\n    plt.scatter(dic[sn_name]['y_time'], y, \n                c='b', label = 'data')\n    plt.errorbar(dic[sn_name]['y_time'], y, \n                 linestyle='', yerr=dic[sn_name]['y_err'], ecolor='b', \n                 alpha=0.7,marker='.',zorder=0)\n    \n    # GP prediction\n    plt.plot(new_x, y_pred, 'r', lw =3, label = 'GP prediction')\n    plt.fill_between(new_x.T[0], y_pred-y_std, y_pred+y_std, color='r', alpha=0.3)\n    \n    if not add_mean:\n        plt.plot(new_x, np.zeros_like(new_x),'k--', label='used mean function')\n    else:\n        plt.plot(dic[sn_name]['y0_time'], dic[sn_name]['y0'],\n                 'k--', label='used mean function')\n    plt.xlim(-12,48)\n    plt.ylim(y.min()-1,\n             y.max()+1)\n    plt.xticks(fontsize=14)\n    plt.yticks(fontsize=14)\n    plt.xlabel('epoch relative to SALT2 $t_0$ (days)', fontsize=20)\n    plt.ylabel('Mag AB + cst.', fontsize=20)\n    plt.title(\"$\\log({\\cal{L}}) = %.2f$ \\n(kernel used: RBF)\"%(log_L), fontsize=20)\n    plt.gca().invert_yaxis()\n    plt.legend(fontsize=18, loc=3)",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ed40e94aecd44dc2b8887d99029a421b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": "aW50ZXJhY3RpdmUoY2hpbGRyZW49KEZsb2F0U2xpZGVyKHZhbHVlPTAuNSwgY29udGludW91c191cGRhdGU9RmFsc2UsIGRlc2NyaXB0aW9uPXUnJFxcc2lnbWEkOicsIG1heD0wLjgsIG1pbj3igKY=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.15",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 2,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}