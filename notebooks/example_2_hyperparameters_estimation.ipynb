{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 2 : Finding Gaussian Process hyperparameters\n",
    "\n",
    "Below some packages to import that will be used for this lesson\n",
    "\n",
    "Cell bellow is here for avoiding scrolling when plot is create within ipython notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines){\n",
       "    return false;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines){\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classical package for manipulating\n",
    "# array, for plotting and interactiv plots.\n",
    "import pylab as plt\n",
    "from matplotlib import gridspec\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "import itertools\n",
    "import emcee\n",
    "import corner\n",
    "import treecorr\n",
    "import treegp\n",
    "from treegp import AnisotropicRBF, eval_kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 5) Maximum Likelihood search of best hyperparameters / kernel (example in 1D):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c54c44a9e14947d79317e0a5735267e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=1.2, continuous_update=False, description='$\\\\sigma$:', max=2.5, min=0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##########################################################################################\n",
    "# EXERCICE 5: Maximum Likelihood search of best hyperparameters / kernel (example in 1D) #\n",
    "##########################################################################################\n",
    "\n",
    "def log_likelihood(param, kernel_type=\"RBF\"):\n",
    "    if param[1] <=0:\n",
    "        return -np.inf\n",
    "    else:\n",
    "        Kernel = \"%f * %s(%f)\"%((param[0]**2, kernel_type, param[1]))\n",
    "        #Kernel = eval_kernel(Kernel)\n",
    "    \n",
    "        gp = treegp.GPInterpolation(kernel=Kernel, optimizer='none', \n",
    "                                    normalize=False, white_noise=0., p0=[3000., 0.,0.],\n",
    "                                    n_neighbors=4, average_fits=None, nbins=20, \n",
    "                                    min_sep=None, max_sep=None)\n",
    "        gp.initialize(x, y, y_err=y_err)\n",
    "        log_L = gp.return_log_likelihood()\n",
    "        return log_L\n",
    "\n",
    "\n",
    "def mcmc_hyperparameters_search(run_mcmc=False):\n",
    "    if run_mcmc:\n",
    "        p0 = [1., 0.5]\n",
    "        np.random.seed(42)\n",
    "        ndim, nwalkers = len(p0), 100\n",
    "        pos = [p0 + 1e-4*np.random.randn(ndim) for i in range(nwalkers)]\n",
    "\n",
    "        sampler = emcee.EnsembleSampler(nwalkers, ndim, log_likelihood)\n",
    "        sampler.run_mcmc(pos, 600)\n",
    "        LABEL = ['$\\sigma$','$l$']\n",
    "        for j in range(ndim):\n",
    "            plt.figure()\n",
    "            for i in range(nwalkers):\n",
    "                plt.plot(sampler.chain[i,:,j],'k', alpha=0.1)\n",
    "            plt.ylabel(LABEL[j], fontsize=20)\n",
    "\n",
    "        samples = sampler.chain[:, 60:, :].reshape((-1, ndim))\n",
    "    \n",
    "        fig = corner.corner(samples, labels=LABEL,\n",
    "                            levels=(0.68, 0.95))\n",
    "        return samples\n",
    "\n",
    "data = np.loadtxt('data/data_1d_grf.txt')\n",
    "x = data[:,0].reshape((len(data[:,0]),1))\n",
    "y = data[:,1]\n",
    "y_err = data[:,2]\n",
    "\n",
    "\n",
    "def gp_regression(x, new_x, y, kernel, y_err=None):\n",
    "    \n",
    "    if y_err is None:\n",
    "        y_err =np.ones_like(y) *1e-10\n",
    "    \n",
    "    gp = treegp.GPInterpolation(kernel=kernel, optimizer='none', \n",
    "                                normalize=False, white_noise=0., p0=[3000., 0.,0.],\n",
    "                                n_neighbors=4, average_fits=None, nbins=20, \n",
    "                                min_sep=None, max_sep=None)\n",
    "    gp.initialize(x, y, y_err=y_err)\n",
    "    y_predict, y_cov = gp.predict(new_x, return_cov=True)\n",
    "    y_std = np.sqrt(np.diag(y_cov))\n",
    "    return y_predict, y_std\n",
    "\n",
    "\n",
    "@interact(sigma = widgets.FloatSlider(value=1.2, min=0.75, max=2.5, step=0.01, description='$\\sigma$:',\n",
    "          disabled=False,\n",
    "          continuous_update=False,\n",
    "          orientation='horizontal',\n",
    "          readout=True,\n",
    "          readout_format='.2f'), \n",
    "          l = widgets.FloatSlider(value=0.6, min=0.4, max=1.5, step=0.01, description='$l$:',\n",
    "          disabled=False,\n",
    "          continuous_update=False,\n",
    "          orientation='horizontal',\n",
    "          readout=True,\n",
    "          readout_format='.2f'),\n",
    "          kernel = widgets.Dropdown(options=['RBF', 'Matern'],\n",
    "                                  value='RBF',\n",
    "                                  description='Kernel:',\n",
    "                                  disabled=False,))\n",
    "def plot_samples(sigma, l, kernel):\n",
    "    \n",
    "    new_x = np.linspace(-24,24, 400).reshape((400,1))\n",
    "    Kernel = \"%f * %s(%f)\"%((sigma**2, kernel, l))\n",
    "    y_pred, y_std = gp_regression(x, new_x, y, Kernel, y_err=y_err)\n",
    "\n",
    "    gs = gridspec.GridSpec(1, 2, width_ratios=[1.5, 1])\n",
    "    plt.figure(figsize=(20,8))\n",
    "    plt.subplot(gs[0])\n",
    "    \n",
    "    # Data\n",
    "    plt.scatter(x, y, c='b', label = 'data')\n",
    "    plt.errorbar(x, y, linestyle='', yerr=y_err, ecolor='b', \n",
    "                 alpha=0.7,marker='.',zorder=0)\n",
    "    \n",
    "    # GP prediction\n",
    "    plt.plot(new_x, y_pred, 'r', lw =3, label = 'GP prediction')\n",
    "    plt.fill_between(new_x.T[0], y_pred-y_std, y_pred+y_std, color='r', alpha=0.3)\n",
    "    \n",
    "    plt.plot(new_x, np.zeros_like(new_x),'k--')\n",
    "    plt.xlim(-24,24)\n",
    "    plt.ylim(-3.,3.)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.xlabel('X', fontsize=20)\n",
    "    plt.ylabel('Y', fontsize=20)\n",
    "    plt.legend(fontsize=18)\n",
    "    \n",
    "    plt.subplot(gs[1])\n",
    "    \n",
    "    distance = np.linspace(0, 2, 40)\n",
    "    coord = np.array([distance, np.zeros_like(distance)]).T\n",
    "    Kernel = eval_kernel(Kernel)\n",
    "    pcf = Kernel.__call__(coord, Y=np.zeros_like(coord))[:,0]\n",
    "    \n",
    "    plt.plot(distance, pcf, 'k', lw=3)\n",
    "    \n",
    "    plt.ylim(0, 2.5**2)\n",
    "    plt.xlim(0, 2)\n",
    "    plt.ylabel('$\\\\xi(|x_i-x_j|)$', fontsize=20)\n",
    "    plt.xlabel('$|x_i-x_j|$', fontsize=20)\n",
    "    plt.title('Used correlation function (%s)'%(kernel), fontsize=16)\n",
    "    \n",
    "    samples = np.loadtxt('data/data_1d_grf_mcmc_likelihood_sampling_%s.txt'%(kernel))\n",
    "    fig = corner.corner(samples, labels=['$\\sigma$','$l$'],\n",
    "                        truths=[sigma, l, ], levels=(0.68, 0.95))\n",
    "    fig.suptitle('Kernel type: ' + kernel + ', $\\log$ likelihood = %.2f'%(log_likelihood([sigma, l], kernel_type=kernel)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 6) 2-point correlation function search of best hyperparameters / kernel (example in 1D) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb307876f4614d45867a1d3a455bbf8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=1.2, continuous_update=False, description='$\\\\sigma$:', max=2.5, min=0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##########################################################################################\n",
    "# EXERCICE 6: Maximum Likelihood search of best hyperparameters / kernel (example in 1D) #\n",
    "##########################################################################################\n",
    "\n",
    "data = np.loadtxt('data/data_1d_grf_4000_points.txt')\n",
    "x = data[:,0].reshape((len(data[:,0]),1))\n",
    "y = data[:,1]\n",
    "y_err = data[:,2]\n",
    "\n",
    "np.random.seed(42)\n",
    "Filter = np.random.choice([True, False, False, False, False], size=len(y))\n",
    "\n",
    "cat = treecorr.Catalog(x=x[:,0], y=np.zeros_like(x[:,0]), k=(y-np.mean(y)), w=1./y_err**2)\n",
    "kk = treecorr.KKCorrelation(min_sep=0.05, max_sep=1.5, nbins=15.)\n",
    "kk.process(cat)\n",
    "delta_distance = kk.meanr\n",
    "xi = kk.xi\n",
    "\n",
    "def gp_regression(x, new_x, y, kernel, y_err=None):\n",
    "    \n",
    "    if y_err is None:\n",
    "        y_err =np.ones_like(y) *1e-10\n",
    "    \n",
    "    gp = treegp.GPInterpolation(kernel=kernel, optimizer='none', \n",
    "                                normalize=False, white_noise=0., p0=[3000., 0.,0.],\n",
    "                                n_neighbors=4, average_fits=None, nbins=20, \n",
    "                                min_sep=None, max_sep=None)\n",
    "    gp.initialize(x, y, y_err=y_err)\n",
    "    y_predict, y_cov = gp.predict(new_x, return_cov=True)\n",
    "    y_std = np.sqrt(np.diag(y_cov))\n",
    "    return y_predict, y_std\n",
    "\n",
    "@interact(sigma = widgets.FloatSlider(value=1.2, min=0.75, max=2.5, step=0.01, description='$\\sigma$:',\n",
    "          disabled=False,\n",
    "          continuous_update=False,\n",
    "          orientation='horizontal',\n",
    "          readout=True,\n",
    "          readout_format='.2f'), \n",
    "          l = widgets.FloatSlider(value=0.6, min=0.4, max=1.5, step=0.01, description='$l$:',\n",
    "          disabled=False,\n",
    "          continuous_update=False,\n",
    "          orientation='horizontal',\n",
    "          readout=True,\n",
    "          readout_format='.2f'),\n",
    "          kernel = widgets.Dropdown(options=['RBF', 'Matern'],\n",
    "                                  value='RBF',\n",
    "                                  description='Kernel:',\n",
    "                                  disabled=False,))\n",
    "def plot_samples(sigma, l, kernel):\n",
    "\n",
    "    y_reduce = y[Filter]\n",
    "    x_reduce = x[Filter]\n",
    "    y_err_reduce = y_err[Filter]\n",
    "    \n",
    "    new_x = np.linspace(-55, 55, 500).reshape((500,1))\n",
    "    Kernel = \"%f * %s(%f)\"%((sigma**2, kernel, l))\n",
    "    y_pred, y_std = gp_regression(x_reduce, new_x, y_reduce, \n",
    "                                  Kernel, y_err=y_err_reduce)\n",
    "\n",
    "    gs = gridspec.GridSpec(1, 2, width_ratios=[1.5, 1])\n",
    "    plt.figure(figsize=(20,8))\n",
    "    plt.subplot(gs[0])\n",
    "    \n",
    "    # Data\n",
    "    plt.scatter(x, y, c='b', label = 'data')\n",
    "    plt.errorbar(x, y, linestyle='', yerr=y_err, ecolor='b', \n",
    "                 alpha=0.7,marker='.',zorder=0)\n",
    "    \n",
    "    # GP prediction\n",
    "    plt.plot(new_x, y_pred, 'r', lw =3, label = 'GP prediction')\n",
    "    plt.fill_between(new_x.T[0], y_pred-y_std, y_pred+y_std, color='r', alpha=0.3)\n",
    "    \n",
    "    plt.plot(new_x, np.zeros_like(new_x),'k--')\n",
    "    plt.xlim(-55, 55)\n",
    "    plt.ylim(-3.,3.)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.xlabel('X', fontsize=20)\n",
    "    plt.ylabel('Y', fontsize=20)\n",
    "    plt.legend(fontsize=18)\n",
    "    \n",
    "    plt.subplot(gs[1])\n",
    "    \n",
    "    distance = np.linspace(0, 2, 40)\n",
    "    coord = np.array([distance, np.zeros_like(distance)]).T\n",
    "    Kernel = eval_kernel(Kernel)\n",
    "    pcf = Kernel.__call__(coord, Y=np.zeros_like(coord))[:,0]\n",
    "    \n",
    "    plt.plot(distance, pcf, 'k', lw=3, label=\"Used correlation function\")\n",
    "    plt.scatter(delta_distance, xi, c='b', s=80, label=\"Measured 2-point correlation function\")\n",
    "    \n",
    "    plt.ylim(0, 2.)\n",
    "    plt.xlim(0, 2)\n",
    "    plt.ylabel('$\\\\xi(|x_i-x_j|)$', fontsize=20)\n",
    "    plt.xlabel('$|x_i-x_j|$', fontsize=20)\n",
    "    plt.legend(fontsize=14)\n",
    "    plt.title('Used correlation function (%s)'%(kernel), fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
